# -*- coding: utf-8 -*-
"""cnnlstm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eEairAamob2L94p39CarYyl0RAdm2agy
"""

!pip install keras_self_attention

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import os
import librosa

seg_len = 16000  # signal split length (in samples) in time domain
seg_ov = int(seg_len * 0.5)  # 50% overlap

def normalize(s):
    # RMS normalization
    new_s = s / np.sqrt(np.sum(np.square((np.abs(s)))) / len(s))
    return new_s

def countclasses(fnames):
    dict_counts = {cls: 0 for cls in classes}
    for name in fnames:
        if name[5] in classes:
            dict_counts[name[5]] += 1
    return dict_counts

def data1d(path):
    fnames = os.listdir(path)
    dict_counts = countclasses(fnames)
    print('Total Data', dict_counts)
    num_cl = len(classes)
    train_dict = {cls: 0 for cls in classes}
    test_dict = {cls: 0 for cls in classes}
    val_dict = {cls: 0 for cls in classes}

    for cname, cnum in dict_counts.items():
        t = round(0.8 * cnum)
        test_dict[cname] = int(cnum - t)
        val_dict[cname] = int(round(0.2 * t))
        train_dict[cname] = int(t - val_dict[cname])
        print('Class:', cname, 'train:', train_dict[cname], 'val:', val_dict[cname], 'test:', test_dict[cname])

    x_train, y_train, x_test, y_test, x_val, y_val = [], [], [], [], [], []

    count = {cls: 0 for cls in classes}

    for name in fnames:
        if name[5] in classes:
            sig, fs = librosa.load(os.path.join(path, name), sr=16000)
            # normalize signal
            data = normalize(sig)
            if len(data) < seg_len:
                pad_len = int(seg_len - len(data))
                pad_rem = int(pad_len % 2)
                pad_len /= 2.0  # Ensure floating-point division
                signal = np.pad(data, (int(pad_len), int(pad_len + pad_rem)), 'constant', constant_values=0)
            elif len(data) > seg_len:
                signal = []
                end = seg_len
                st = 0
                while end < len(data):
                    signal.append(data[st:end])
                    st = st + seg_ov
                    end = st + seg_len
                signal = np.array(signal)
                if end >= len(data):
                    num_zeros = int(end - len(data))
                    if num_zeros > 0:
                        n1 = np.array(data[st:end])
                        n2 = np.zeros([num_zeros])
                        s = np.concatenate([n1, n2], 0)
                    else:
                        s = np.array(data[int(st):int(end)])
                signal = np.vstack([signal, s])
            else:
                signal = data

            if count[name[5]] < train_dict[name[5]]:
                if signal.ndim > 1:
                    for i in range(signal.shape[0]):
                        x_train.append(signal[i])
                        y_train.append(name[5])
                else:
                    x_train.append(signal)
                    y_train.append(name[5])
            else:
                if (count[name[5]] - train_dict[name[5]]) < val_dict[name[5]]:
                    if signal.ndim > 1:
                        for i in range(signal.shape[0]):
                            x_val.append(signal[i])
                            y_val.append(name[5])
                    else:
                        x_val.append(signal)
                        y_val.append(name[5])
                else:
                    if signal.ndim > 1:
                        for i in range(signal.shape[0]):
                            x_test.append(signal[i])
                            y_test.append(name[5])
                    else:
                        x_test.append(signal)
                        y_test.append(name[5])
            count[name[5]] += 1

    return np.float32(x_train), y_train, np.float32(x_test), y_test, np.float32(x_val), y_val

def string2num(y):
    y_map = {cls: idx for idx, cls in enumerate(classes)}
    y1 = [y_map[i] for i in y]
    return np.float32(np.array(y1))

def load_data():
    x_tr, y_tr, x_t, y_t, x_v, y_v = data1d(datapath)
    y_tr = string2num(y_tr)
    y_t = string2num(y_t)
    y_v = string2num(y_v)
    return x_tr, y_tr, x_t, y_t, x_v, y_v

datapath = r'/content/drive/MyDrive/wav'
classes = ['W', 'L', 'E', 'A', 'F', 'T', 'N']  # 7 classes

from keras.models import Model, Sequential
from keras import optimizers
from keras.layers import Input, Conv1D, BatchNormalization, MaxPooling1D, LSTM, Dense, Activation
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.models import load_model
from keras_self_attention import SeqSelfAttention

from keras import initializers
import numpy as np
from keras.utils import to_categorical

def emo1d(input_shape, num_classes, args):
    model = Sequential(name='Emo1D')

    # LFLB1
    model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same', input_shape=input_shape,
                     kernel_initializer=initializers.GlorotNormal(seed=42)))
    model.add(BatchNormalization())
    model.add(MaxPooling1D(pool_size=4, strides=4))

    # LFLB2
    model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same',
                     kernel_initializer=initializers.GlorotNormal(seed=42)))
    model.add(BatchNormalization())
    model.add(MaxPooling1D(pool_size=4, strides=4))

    # LFLB3
    model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same',
                     kernel_initializer=initializers.GlorotNormal(seed=42)))
    model.add(BatchNormalization())
    model.add(MaxPooling1D(pool_size=4, strides=4))

    # LFLB4
    model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same',
                     kernel_initializer=initializers.GlorotNormal(seed=42)))
    model.add(BatchNormalization())
    model.add(MaxPooling1D(pool_size=4, strides=4))

    # LSTM layer
    model.add(LSTM(units=args.num_fc, return_sequences=True))
    model.add(SeqSelfAttention(attention_activation='tanh'))
    model.add(LSTM(units=args.num_fc, return_sequences=False))

    # Fully connected layer
    model.add(Dense(units=num_classes, activation='softmax'))

    # Model compilation
    opt = optimizers.Adam(learning_rate=args.learning_rate)
    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

    return model

def train(model, x_tr, y_tr, x_val, y_val, args):
    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)
    mc = ModelCheckpoint('test_model.h5', monitor='val_accuracy', mode='max', verbose=1,
                         save_best_only=True)
    history = model.fit(x_tr, y_tr, epochs=args.num_epochs, batch_size=args.batch_size, validation_data=(x_val, y_val),
                        callbacks=[es, mc])
    return model

def test(model, x_t, y_t):
    saved_model = load_model('test_model.h5', custom_objects={'SeqSelfAttention': SeqSelfAttention})
    score = saved_model.evaluate(x_t, y_t, batch_size=20)
    print(score)
    return score

def loadData():
    x_tr, y_tr, x_t, y_t, x_val, y_val = load_data()
    x_tr = x_tr.reshape(-1, x_tr.shape[1], 1)
    x_t = x_t.reshape(-1, x_t.shape[1], 1)
    x_val = x_val.reshape(-1, x_val.shape[1], 1)
    y_tr = to_categorical(y_tr)
    y_t = to_categorical(y_t)
    y_val = to_categorical(y_val)
    return x_tr, y_tr, x_t, y_t, x_val, y_val

if __name__ == "__main__":
    class Args:
        num_fc = 128
        batch_size = 32
        num_epochs = 100
        learning_rate = 5e-5
    args = Args()

    x_tr, y_tr, x_t, y_t, x_val, y_val = loadData()
    model = emo1d(input_shape=x_tr.shape[1:], num_classes=len(np.unique(np.argmax(y_tr, axis=1))), args=args)

    model = train(model, x_tr, y_tr, x_val, y_val, args=args)

    score = test(model, x_t, y_t)

import matplotlib.pyplot as plt

# Accuracy and validation accuracy lists
accuracy = [0.3986, 0.5868, 0.6803, 0.7802, 0.8410, 0.8768, 0.9151, 0.9157, 0.9316, 0.9487, 0.9534]
val_acc = [0.3326, 0.3884, 0.5558, 0.6116, 0.6786, 0.6205, 0.7054, 0.6684, 0.7274, 0.7518, 0.7696]

# Epochs (x-axis)
epochs = range(1,len(accuracy) * 5 + 1,5)

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(epochs, accuracy, label='Accuracy', marker='o')
plt.plot(epochs, val_acc, label='Validation Accuracy', marker='s')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

print(score)
print('Final accuracy of the model :',score[1]*100)

from keras.models import load_model
from keras_self_attention import SeqSelfAttention
import numpy as np
import os
import librosa
# Load the saved model
saved_model = load_model('test_model.h5', custom_objects={'SeqSelfAttention': SeqSelfAttention})

# Load the input audio file
input_file_path = '/content/drive/MyDrive/wav/03a01Fa.wav'
signal, sr = librosa.load(input_file_path, sr=16000)

# Normalize the signal
data = normalize(signal)
seg_len = 16000
seg_ov = int(seg_len * 0.5)
input_length = len(data)
max_input_length = seg_len  # Assuming seg_len is the maximum input length expected by the model
if input_length > max_input_length:
    print("Warning: Input length exceeds maximum length. Truncating or processing in segments may be required.")

# Pad or truncate the data to match the model's input shape
if input_length < max_input_length:
    pad_length = max_input_length - input_length
    data = np.pad(data, (0, pad_length), mode='constant', constant_values=0)
elif input_length > max_input_length:
    data = data[:max_input_length]

# Reshape the data for the model
x_input = data.reshape(-1, max_input_length, 1)

# Make predictions using the loaded model
predictions = saved_model.predict(x_input)

# Decode the predictions to get the emotion labels
emotions = ['W', 'L', 'E', 'A', 'F', 'T', 'N']
emotion_mapping = {
    'W': 'Anger',
    'L': 'Boredom',
    'E': 'Disgust',
    'A': 'Anxiety',
    'F': 'Happiness',
    'T': 'Sadness',
    'N': 'Neutral'
} # Assuming these are the emotion labels
predicted_emotions = [emotions[np.argmax(pred)] for pred in predictions]
predicted_emotions_names = [emotion_mapping[emotion] for emotion in predicted_emotions]
# Display the predicted emotions
for i, emotion_name in enumerate(predicted_emotions_names):
    print(f"Segment {i+1}: Predicted Emotion - {emotion_name}")